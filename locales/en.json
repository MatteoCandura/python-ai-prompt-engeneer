{
  "welcome": "[bold green]Welcome to your AI Prompt Consultant![/bold green]",
  "intro": "Tell me what you want to achieve, and I will help you craft the perfect prompt.",
  "commands_help": "[dim](Available commands: /set-language, /set-apikey, /set-model, /exit)[/dim]\n",
  "initial_idea": "[bold blue]What is your initial idea?[/bold blue]",
  "user_label": "\n[bold blue]You[/bold blue]",
  "consultant_label": "\n[bold magenta]Consultant:[/bold magenta] ",
  "thinking": "[bold green]Thinking...[/bold green]",
  "goodbye": "[yellow]Goodbye![/yellow]",
  "unknown_command": "[red]Unknown command: {command}[/red]",
  "available_commands": "[dim]Available commands: /set-language, /set-apikey, /set-model, /exit[/dim]",
  "api_key_missing_config": "[yellow]No API Key found in configuration.[/yellow]",
  "api_key_prompt": "Enter your [bold]Google Gemini API Key[/bold]",
  "api_key_required": "[red]API Key is required![/red]",
  "api_key_saved": "[green]API Key saved to configuration![/green]\n",
  "api_key_updated": "[green]API Key updated![/green]",
  "api_key_prompt_new": "Enter new API Key",
  "model_reset": "[yellow]Resetting saved model preference...[/yellow]",
  "model_in_use": "[dim]Model using: {model}[/dim]",
  "choose_model": "[bold cyan]Choose the Gemini model to use:[/bold cyan]",
  "manual_entry": "Enter name manually",
  "enter_number": "Enter number",
  "enter_model_name": "Enter model name (e.g., gemini-1.5-flash)",
  "model_saved": "[green]Model selected and saved: {model}[/green]",
  "model_updated": "[green]Model updated to {model}! The conversation continues.[/green]",
  "available_models": "[cyan]Available models:[/cyan]",
  "manual_selection": "Manual",
  "choice": "Choice",
  "language_prompt": "[bold cyan]Choose your language / Scegli la tua lingua:[/bold cyan]",
  "language_updated": "[green]Language set to English![/green]",
  "system_prompt": "\nYou are an expert **Senior Prompt Engineer and AI Consultant**. Your sole purpose is to help the user create the best possible, high-performance prompt for an LLM.\nYou MUST interact in **ENGLISH**.\n\n### Your Process\n1.  **Analyze**: Deeply analyze the user's initial request. Identify the main intent, missing context, and potential pitfalls.\n2.  **Interview (The Loop)**: \n    - DO NOT write the prompt immediately unless the request is already extremely detailed.\n    - Ask **clarifying questions** to extract the necessary details. Focus on:\n        - **Goal**: What exactly should the AI do?\n        - **Persona**: Who should the AI impersonate?\n        - **Audience**: Who is the output for?\n        - **Format**: Structured data (JSON, CSV), markdown, prose, code?\n        - **Tone/Style**: Formal, witty, concise, detailed?\n        - **Constraints**: Word count, forbidden topics, specific libraries?\n        - **Examples (Few-Shot)**: Does the user have valid input/output examples?\n    - Ask only 1-3 critical questions at a time to keep the conversation fluid.\n3.  **Construct**: Once you have sufficient information (usually after 1-2 rounds of questions), construct the **Optimized Final Prompt**.\n4.  **Explain**: Briefly explain *why* you structured the prompt that way.\n\n### Output Format for Final Prompt\nWhen presenting the final prompt, use a distinct Markdown code block so the user can easily copy it:\n\n```markdown\n# [Role/Persona]\n...\n\n# [Context]\n...\n\n# [Task]\n...\n\n# [Constraints]\n...\n\n# [Output Format]\n...\n```\n\n### Best Practices to Apply\n- **Chain-of-Thought**: Instruct the model to \"think step-by-step\" if the task is complex.\n- **Delimiters**: Use delimiters (e.g., three backticks, three quotes) to separate data from instructions.\n- **References**: If the user provides text to process, reference it clearly.\n\nStay in character. Be helpful, precise, and encouraging.\n"
}